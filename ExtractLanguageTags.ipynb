{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LANGUAGE SCRIPTS.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python2",
      "display_name": "Python 2"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "WY5iPZqIRru9",
        "colab_type": "code",
        "outputId": "7377e1d0-ded1-47ff-9279-3d0db5730d1a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!pip install pycld2\n",
        "!pip install -U git+https://github.com/aboSamoor/polyglot.git@master\n",
        "\n",
        "!pip install fasttext\n",
        "!wget -O /tmp/lid.176.bin https://dl.fbaipublicfiles.com/fasttext/supervised-models/lid.176.bin"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pycld2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/21/d2/8b0def84a53c88d0eb27c67b05269fbd16ad68df8c78849e7b5d65e6aec3/pycld2-0.41.tar.gz (41.4MB)\n",
            "\u001b[K     |████████████████████████████████| 41.4MB 110kB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pycld2\n",
            "  Building wheel for pycld2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pycld2: filename=pycld2-0.41-cp27-cp27mu-linux_x86_64.whl size=9831801 sha256=5762c1f98822ceec62a65e84802c20313dfc8543582aee45d5ff3872f71770ed\n",
            "  Stored in directory: /root/.cache/pip/wheels/c6/8f/e9/08a1a8932a490175bd140206cd86a3dbcfc70498100de11079\n",
            "Successfully built pycld2\n",
            "Installing collected packages: pycld2\n",
            "Successfully installed pycld2-0.41\n",
            "Collecting git+https://github.com/aboSamoor/polyglot.git@master\n",
            "  Cloning https://github.com/aboSamoor/polyglot.git (to revision master) to /tmp/pip-req-build-7qwue4\n",
            "  Running command git clone -q https://github.com/aboSamoor/polyglot.git /tmp/pip-req-build-7qwue4\n",
            "Requirement already satisfied, skipping upgrade: futures>=2.1.6 in /usr/local/lib/python2.7/dist-packages (from polyglot==16.7.4) (3.2.0)\n",
            "Collecting PyICU>=1.8\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/57/b2/66a58057a537527d7307576f2d32f239cc411b911401276d6922caa94755/PyICU-2.4.3.tar.gz (219kB)\n",
            "\u001b[K     |████████████████████████████████| 225kB 2.7MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: pycld2>=0.3 in /usr/local/lib/python2.7/dist-packages (from polyglot==16.7.4) (0.41)\n",
            "Collecting morfessor>=2.0.2a1\n",
            "  Downloading https://files.pythonhosted.org/packages/af/5e/760a41def80f7e48e4f95937a8de73057871f655c0ec459f7aff3c1f95a2/Morfessor-2.0.6.tar.gz\n",
            "Requirement already satisfied, skipping upgrade: six>=1.7.3 in /usr/local/lib/python2.7/dist-packages (from polyglot==16.7.4) (1.12.0)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.6.1 in /usr/local/lib/python2.7/dist-packages (from polyglot==16.7.4) (1.16.4)\n",
            "Requirement already satisfied, skipping upgrade: wheel>=0.23.0 in /usr/local/lib/python2.7/dist-packages (from polyglot==16.7.4) (0.34.2)\n",
            "Building wheels for collected packages: polyglot, PyICU, morfessor\n",
            "  Building wheel for polyglot (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for polyglot: filename=polyglot-16.7.4-py2.py3-none-any.whl size=70644 sha256=cc983eab2b59a9ba8d8f629e59f555384f7c6b11ea0648c43ffc9a19e3736145\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-Kwf4bC/wheels/42/d9/73/345c7ae8554299ff8b31635d64eb8455fd591385fa734cdbef\n",
            "  Building wheel for PyICU (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for PyICU: filename=PyICU-2.4.3-cp27-cp27mu-linux_x86_64.whl size=872618 sha256=71d339aba3a5c32fa64fce0ff363d1f9165061ad5e8cac9464e9d20ece8f2cd9\n",
            "  Stored in directory: /root/.cache/pip/wheels/ca/14/f9/1d75d2d4be2e0169d986ccde156e25d9c772c91602dff3acc9\n",
            "  Building wheel for morfessor (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for morfessor: filename=Morfessor-2.0.6-cp27-none-any.whl size=35786 sha256=10b3e3737020bbc3a1b92ed804bccd4c7af36c35373b7b7373df4fa3538bf291\n",
            "  Stored in directory: /root/.cache/pip/wheels/a2/9f/7b/38a21d89b744203016bff6e3df79579f83ef4a9a04f205e583\n",
            "Successfully built polyglot PyICU morfessor\n",
            "Installing collected packages: PyICU, morfessor, polyglot\n",
            "Successfully installed PyICU-2.4.3 morfessor-2.0.6 polyglot-16.7.4\n",
            "Collecting ftfy<5\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/21/5d/9385540977b00df1f3a0c0f07b7e6c15b5e7a3109d7f6ae78a0a764dab22/ftfy-4.4.3.tar.gz (50kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 1.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: html5lib in /usr/local/lib/python2.7/dist-packages (from ftfy<5) (1.0.1)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python2.7/dist-packages (from ftfy<5) (0.1.7)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python2.7/dist-packages (from html5lib->ftfy<5) (1.12.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python2.7/dist-packages (from html5lib->ftfy<5) (0.5.1)\n",
            "Building wheels for collected packages: ftfy\n",
            "  Building wheel for ftfy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ftfy: filename=ftfy-4.4.3-cp27-none-any.whl size=41071 sha256=834dded477e880cc634fc129d9729d068bfe770807e945a6736615dee58971cc\n",
            "  Stored in directory: /root/.cache/pip/wheels/37/54/00/d320239bfc8aad1455314f302dd82a75253fc585e17b81704e\n",
            "Successfully built ftfy\n",
            "Installing collected packages: ftfy\n",
            "Successfully installed ftfy-4.4.3\n",
            "Collecting fasttext\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f8/85/e2b368ab6d3528827b147fdb814f8189acc981a4bc2f99ab894650e05c40/fasttext-0.9.2.tar.gz (68kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 1.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: pybind11>=2.2 in /usr/local/lib/python2.7/dist-packages (from fasttext) (2.5.0)\n",
            "Requirement already satisfied: setuptools>=0.7.0 in /usr/local/lib/python2.7/dist-packages (from fasttext) (44.1.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python2.7/dist-packages (from fasttext) (1.16.4)\n",
            "Building wheels for collected packages: fasttext\n",
            "  Building wheel for fasttext (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fasttext: filename=fasttext-0.9.2-cp27-cp27mu-linux_x86_64.whl size=2582462 sha256=907e197e9bb5255af0916fd7224d86b85379c6afd0d5aadce7d02fcf993e8557\n",
            "  Stored in directory: /root/.cache/pip/wheels/98/ba/7f/b154944a1cf5a8cee91c154b75231136cc3a3321ab0e30f592\n",
            "Successfully built fasttext\n",
            "Installing collected packages: fasttext\n",
            "Successfully installed fasttext-0.9.2\n",
            "--2020-05-26 21:24:08--  https://dl.fbaipublicfiles.com/fasttext/supervised-models/lid.176.bin\n",
            "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 104.22.74.142, 104.22.75.142, 2606:4700:10::6816:4b8e, ...\n",
            "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|104.22.74.142|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 131266198 (125M) [application/octet-stream]\n",
            "Saving to: ‘/tmp/lid.176.bin’\n",
            "\n",
            "/tmp/lid.176.bin    100%[===================>] 125.18M  13.3MB/s    in 10s     \n",
            "\n",
            "2020-05-26 21:24:19 (12.3 MB/s) - ‘/tmp/lid.176.bin’ saved [131266198/131266198]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sEqjhsqq_6OH",
        "colab_type": "code",
        "outputId": "1f64e450-c76c-412e-8894-f6d2aa985414",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S4NGi4m0O_Vg",
        "colab_type": "code",
        "outputId": "c6da2672-484b-4cbb-ef1c-8677383dd67c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from __future__ import print_function, division\n",
        "\n",
        "from polyglot.detect import Detector\n",
        "from ftfy import fix_encoding\n",
        "from collections import Counter\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import re\n",
        "import csv\n",
        "import fasttext\n",
        "\n",
        "emoji_pattern = re.compile(\"[\"\n",
        "        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
        "        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
        "        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
        "        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
        "        u\"\\U0001F1F2-\\U0001F1F4\"  # Macau flag\n",
        "        u\"\\U0001F1E6-\\U0001F1FF\"  # flags\n",
        "        u\"\\U0001F600-\\U0001F64F\"\n",
        "        u\"\\U00002702-\\U000027B0\"\n",
        "        u\"\\U000024C2-\\U0001F251\"\n",
        "        u\"\\U0001f926-\\U0001f937\"\n",
        "        u\"\\U0001F1F2\"\n",
        "        u\"\\U0001F1F4\"\n",
        "        u\"\\U0001F620\"\n",
        "        u\"\\u200d\"\n",
        "        u\"\\u2640-\\u2642\"\n",
        "        \"]+\", flags=re.UNICODE)\n",
        "\n",
        "hashtag_pattern = re.compile(u\"#\\w+\")\n",
        "\n",
        "userhandle_pattern = re.compile(u\"@(\\w){1,30}\")\n",
        "\n",
        "def fix_text(text):\n",
        "  # Emoji remover\n",
        "  text = emoji_pattern.sub(r'', text)\n",
        "  # Hashtag remover\n",
        "  text = hashtag_pattern.sub(r'', text)\n",
        "  # Userhandle remover\n",
        "  text = userhandle_pattern.sub(r'', text)\n",
        "  # Link remover\n",
        "  text = re.sub(r\"http\\S+\", r'', text)\n",
        "  # Punctation remover\n",
        "  text = re.sub(ur'[.,\\/#!?$%\\^&\\*;:{}=\\-_`~()]', r'', text)\n",
        "  # New line to space character\n",
        "  text = re.sub(r\"[\\r\\n]\", \" \", text)\n",
        "  # Reduce multiple space characters to only one\n",
        "  text = re.sub(r\"\\s\\s+\", \" \", text)\n",
        "  # Lowercase all characters\n",
        "  text = text.lower()\n",
        "\n",
        "  return text\n",
        "\n",
        "def label_lang_polyglot(text):\n",
        "  try:\n",
        "    lang = Detector(text, quiet=True).language.code\n",
        "  except:\n",
        "    lang = \"err\"\n",
        "  return lang\n",
        "\n",
        "def label_lang_fasttext(text):\n",
        "  try:\n",
        "    lang = str(model.predict(text)[0][0]).split('__')[2]\n",
        "  except:\n",
        "    lang = \"err\"\n",
        "  return lang\n",
        "\n",
        "PRETRAINED_MODEL_PATH = '/tmp/lid.176.bin'\n",
        "model = fasttext.load_model(PRETRAINED_MODEL_PATH)\n",
        "\n",
        "def extract_majority_vote(text):\n",
        "  languages = text.split(\"-\")\n",
        "\n",
        "  i = 0\n",
        "  while i < len(languages):\n",
        "    if languages[i] == 'un':\n",
        "      languages[i] = 'und'\n",
        "    i = i + 1\n",
        "\n",
        "  languages = Counter(languages)\n",
        "  max_count = 0\n",
        "  max_lang = \"conflict\"\n",
        "  for lang in languages:\n",
        "    if languages[lang] > len(languages)/2:\n",
        "      max_lang = lang\n",
        "      break\n",
        "\n",
        "  return max_lang\n",
        "\n",
        "LANG_CODES = [\"BCL\", \"CBK\" ,\"CEB\", \"EN\", \"ILO\", \"PAM\", \"TL\", \"WAR\", \"UN\", \"UND\", \"conflict\"]\n",
        "\n",
        "def extract_language_counts(s):\n",
        "  lang_dict = {}\n",
        "  _sum = 0\n",
        "  for code in LANG_CODES:\n",
        "    lang_dict[code.lower()] = len(s[s == code.lower()])\n",
        "    _sum = _sum + len(s[s == code.lower()])\n",
        "  lang_dict['other'] = len(s) - _sum\n",
        "  return lang_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q0VFA2_EnesL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# FILE PATHS REMOVED FROM COLAB\n",
        "INSTAGRAM_POSTS_FILE_PATH\n",
        "TWITTER_TWEETS_FILE_PATH\n",
        "INSTAGRAM_LANG_TAGS_FILE_PATH\n",
        "TWITTER_LANG_TAGS_FILE_PATH"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FOGWYzrfRc83",
        "colab_type": "code",
        "outputId": "6481ec35-fa55-4938-d395-11da678c0501",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "print(\"Loading Instagram posts...\")\n",
        "instagram_df = pd.read_csv(\n",
        "\tINSTAGRAM_POSTS_FILE_PATH, \n",
        "\tencoding=\"utf-8\",\n",
        "\tquoting=csv.QUOTE_ALL)\n",
        "instagram_df.set_index(\"InstaPostID\", inplace=True)\n",
        "instagram_df = instagram_df[['UserID', 'Caption']]\n",
        "\n",
        "print(\"Loading Twitter posts...\")\n",
        "twitter_df = pd.read_csv(\n",
        "\tTWITTER_TWEETS_FILE_PATH, \n",
        "\tencoding=\"utf-8\",\n",
        "\tquoting=csv.QUOTE_ALL)\n",
        "twitter_df.set_index(\"TweetID\", inplace=True)\n",
        "twitter_df = twitter_df[['UserID', 'Text', 'Language']]\n",
        "twitter_df['Text'] = twitter_df['Text'].fillna(\"\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading Instagram posts...\n",
            "Loading Twitter posts...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hTP7I1OC-RDB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "instagram_df.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_jlpuo5lAYsn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "twitter_df.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y04OMvfmqCG4",
        "colab_type": "code",
        "outputId": "03cba6e5-e58b-43e7-f27b-5c81f5abb704",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        }
      },
      "source": [
        "print(\"INITIAL STATISTICS:\")\n",
        "print(\"TOTAL TWITTER POSTS: %d\" % len(twitter_df))\n",
        "print(\"TOTAL INSTAGRAM POSTS: %d\" % len(instagram_df))\n",
        "print(\"TOTAL INSTAGRAM POSTS W/O TEXT: %d\" % len(instagram_df[instagram_df.Caption.isna()]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INITIAL STATISTICS:\n",
            "TOTAL TWITTER POSTS: 4018628\n",
            "TOTAL INSTAGRAM POSTS: 195757\n",
            "TOTAL INSTAGRAM POSTS W/O TEXT: 17107\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fc1SR0thRkcB",
        "colab_type": "code",
        "outputId": "08f66116-f2ad-4c5f-8701-10d0cd9c9764",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "print(\"Removing captions w/ no text...\")\n",
        "instagram_df = instagram_df[~instagram_df.Caption.isna()]\n",
        "print(\"done.\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Removing captions w/ no text...\n",
            "done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rj1qmKfqluZ0",
        "colab_type": "code",
        "outputId": "dad365d4-fafe-4129-fe15-a13f9920a494",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "print(\"Fixing text...\")\n",
        "instagram_df['Caption'] = instagram_df['Caption'].apply(fix_text)\n",
        "print(\"Instagram done.\")\n",
        "twitter_df['Text'] = twitter_df['Text'].apply(fix_text)\n",
        "print(\"Twitter done.\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fixing text...\n",
            "Instagram done.\n",
            "Twitter done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-uTw5_CdmMl5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "instagram_df.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aWRp3kA_Oz88",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "twitter_df.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eOcUTLlJXPTG",
        "colab_type": "code",
        "outputId": "bbc025fc-8646-4aa6-ce83-3209af8e39dc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "print(\"Detecting language polyglot...\")\n",
        "instagram_df['Lang_Polyglot'] = instagram_df['Caption'].apply(label_lang_polyglot)\n",
        "twitter_df['Lang_Polyglot'] = twitter_df['Text'].apply(label_lang_polyglot)\n",
        "\n",
        "print(\"Detecting language fasttext...\")\n",
        "instagram_df['Lang_FastText'] = instagram_df['Caption'].apply(label_lang_fasttext)\n",
        "twitter_df['Lang_FastText'] = twitter_df['Text'].apply(label_lang_fasttext)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Detecting language polyglot...\n",
            "Detecting language fasttext...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YZZPHxirK3m7",
        "colab_type": "code",
        "outputId": "65be4c0c-a382-4b57-935b-30058a0eb23e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(\"Extracting results (single label)...\")\n",
        "instagram_df['LangID_Combined'] = instagram_df['Lang_Polyglot'] + \"-\" + instagram_df['Lang_FastText']\n",
        "twitter_df['LangID_Combined'] = twitter_df['Language'] + \"-\" + twitter_df['Lang_Polyglot'] + \"-\" + twitter_df['Lang_FastText']"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Extracting results (single label)...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wVS1wKIm184X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "instagram_df['MajorityVote'] = instagram_df['LangID_Combined'].apply(extract_majority_vote)\n",
        "twitter_df['MajorityVote'] = twitter_df['LangID_Combined'].apply(extract_majority_vote)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fg_fnp3rIsJo",
        "colab_type": "code",
        "outputId": "80584fb5-0bbb-4e0e-fe10-6d67cf1a4ed9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(\"Saving files...\")\n",
        "instagram_df.to_csv(\"InstaPostsWLanguage.csv\", encoding='utf-8', quoting=csv.QUOTE_ALL)\n",
        "twitter_df.to_csv(\"TwitaPostsWLanguage.csv\", encoding='utf-8', quoting=csv.QUOTE_ALL)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saving files...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pDSN9V1uOCXU",
        "colab_type": "text"
      },
      "source": [
        "#ALL SCRIPTS FOR TOTAL LANGAUGE DISTRIBUTION"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9lHC3t2L24Js",
        "colab_type": "code",
        "outputId": "8850f680-381b-42aa-de7c-8c87d15c272f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 243
        }
      },
      "source": [
        "all_languages = {\n",
        "    'Twitter Tag': extract_language_counts(twitter_df['Language']),\n",
        "    'Polyglot': extract_language_counts(twitter_df['Lang_Polyglot']),\n",
        "    'FastText': extract_language_counts(twitter_df['Lang_FastText']),\n",
        "    'Majority Vote': extract_language_counts(twitter_df['MajorityVote']),\n",
        "}\n",
        "\n",
        "df_tweet_lang_table = pd.DataFrame.from_dict(all_languages)\n",
        "print(df_tweet_lang_table)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "          FastText  Majority Vote  Polyglot  Twitter Tag\n",
            "bcl            358              0         0            0\n",
            "cbk            479              0         0            0\n",
            "ceb         115678          34128    121877            0\n",
            "conflict         0         661954         0            0\n",
            "en         2244161        1855462   2094950      1563939\n",
            "ilo           8605              0         0            0\n",
            "other       685386          41862    540371       245900\n",
            "pam            634              0         0            0\n",
            "tl          933657        1264173   1040594      1945342\n",
            "un               0              0    171582            0\n",
            "und              0         159338         0       263447\n",
            "war          29670           1711     49254            0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ml5s5EFMKrZd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for code in LANG_CODES:\n",
        "  print(code, twitter_df['Text'][twitter_df['Lang_FastText'] == code.lower()][:10])\n",
        "  print(\"==========\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yvyEBkGNF9Mz",
        "colab_type": "code",
        "outputId": "7e1f94ab-eb5b-42a6-dbf9-9446253c94d2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 243
        }
      },
      "source": [
        "all_languages = {\n",
        "    'Polyglot': extract_language_counts(instagram_df['Lang_Polyglot']),\n",
        "    'FastText': extract_language_counts(instagram_df['Lang_FastText']),\n",
        "    'Majority Vote': extract_language_counts(instagram_df['MajorityVote']),\n",
        "}\n",
        "\n",
        "df_ig_lang_table = pd.DataFrame.from_dict(all_languages)\n",
        "print(df_ig_lang_table)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "          FastText  Majority Vote  Polyglot\n",
            "bcl              7              0         0\n",
            "cbk              9              0         0\n",
            "ceb           1329            192       781\n",
            "conflict         0          46476         0\n",
            "en          147892         123962    135450\n",
            "ilo             73              0         0\n",
            "other        19455            918     13609\n",
            "pam              6              0         0\n",
            "tl            9654           7089     10966\n",
            "un               0              0     17191\n",
            "und              0              0         0\n",
            "war            225             13       653\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FEm55GbpcBIP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cp TwitaPostsWLanguage.csv TWITTETR_LANG_TAGS_FILE_PATH\n",
        "!cp InstaPostsWLanguage.csv INSTAGRAM_LANG_TAGS_FILE_PATH"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3W7LKgifbdNQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}